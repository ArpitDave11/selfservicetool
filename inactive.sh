#!/bin/bash
# =============================================================================
# AutoSys Job Inactivation Script - Parallel Execution
# =============================================================================
# This script reads job names from a .txt file and sets them to INACTIVE
# status using parallel threads for faster execution.
#
# The .txt file is generated by generate_inactive_jobs.py (Databricks notebook)
#
# Usage: ./inactive.sh --file /path/to/inactive_jobs.txt --threads 20 --retries 3
# =============================================================================

set -o pipefail

# =============================================================================
# CONFIGURATION DEFAULTS
# =============================================================================
JOBS_FILE=""
NUM_THREADS=20
MAX_RETRIES=3
RETRY_DELAY=5
DRY_RUN=false

# Paths
AUTOSYS_ENV_SCRIPT="/mnt/ingestion/autosys/esl.env"
LOG_DIR="/mnt/ingestion/autosys/logs"
TEMP_DIR="/tmp/inactive_$$"

# Timestamp for this run
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_FILE="${LOG_DIR}/inactive_${TIMESTAMP}.log"
FAILURES_CSV="${LOG_DIR}/inactive_failures_${TIMESTAMP}.csv"

# =============================================================================
# COLOR CODES FOR OUTPUT
# =============================================================================
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# =============================================================================
# LOGGING FUNCTIONS
# =============================================================================
log_info() {
    local msg="[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1"
    echo -e "${BLUE}${msg}${NC}"
    echo "$msg" >> "$LOG_FILE"
}

log_success() {
    local msg="[$(date '+%Y-%m-%d %H:%M:%S')] [SUCCESS] $1"
    echo -e "${GREEN}${msg}${NC}"
    echo "$msg" >> "$LOG_FILE"
}

log_warning() {
    local msg="[$(date '+%Y-%m-%d %H:%M:%S')] [WARNING] $1"
    echo -e "${YELLOW}${msg}${NC}"
    echo "$msg" >> "$LOG_FILE"
}

log_error() {
    local msg="[$(date '+%Y-%m-%d %H:%M:%S')] [ERROR] $1"
    echo -e "${RED}${msg}${NC}"
    echo "$msg" >> "$LOG_FILE"
}

log_thread() {
    local thread_id=$1
    local msg=$2
    local full_msg="[$(date '+%Y-%m-%d %H:%M:%S')] [Thread $thread_id] $msg"
    echo "$full_msg"
    # Thread-safe write to log file using flock
    (
        flock -x 200
        echo "$full_msg" >> "$LOG_FILE"
    ) 200>"${TEMP_DIR}/.log_lock"
}

# =============================================================================
# USAGE/HELP
# =============================================================================
show_help() {
    cat << EOF
AutoSys Job Inactivation Script - Parallel Execution

Usage: $(basename "$0") [OPTIONS]

Required:
  -f, --file PATH      Path to jobs .txt file (one job name per line)

Optional:
  -t, --threads NUM    Number of parallel threads (default: 20)
  -r, --retries NUM    Max retries per failed job (default: 3)
  -d, --dry-run        Print commands without executing
  -h, --help           Show this help message

Examples:
  $(basename "$0") --file /dbfs/mnt/dataops/config/inactive_jobs.txt --threads 20
  $(basename "$0") --file /path/to/jobs.txt --threads 10 --retries 5
  $(basename "$0") --file /path/to/jobs.txt --dry-run

Notes:
  - The jobs .txt file should contain one job name per line
  - Job names are already fully qualified (e.g., WMA_ESL_5481_PRD_DMSH_PRCSSNG_FILENAME)
  - Generate the .txt file using generate_inactive_jobs.py in Databricks

EOF
    exit 0
}

# =============================================================================
# ARGUMENT PARSING
# =============================================================================
parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            -f|--file)
                JOBS_FILE="$2"
                shift 2
                ;;
            -t|--threads)
                NUM_THREADS="$2"
                shift 2
                ;;
            -r|--retries)
                MAX_RETRIES="$2"
                shift 2
                ;;
            -d|--dry-run)
                DRY_RUN=true
                shift
                ;;
            -h|--help)
                show_help
                ;;
            *)
                log_error "Unknown option: $1"
                show_help
                ;;
        esac
    done

    # Validate required arguments
    if [[ -z "$JOBS_FILE" ]]; then
        log_error "Jobs file (-f, --file) is required"
        show_help
    fi
}

# =============================================================================
# PRE-FLIGHT CHECKS
# =============================================================================
preflight_checks() {
    log_info "Running pre-flight checks..."

    # Check if jobs file exists
    if [[ ! -f "$JOBS_FILE" ]]; then
        log_error "Jobs file not found: $JOBS_FILE"
        exit 1
    fi
    log_info "  [OK] Jobs file exists: $JOBS_FILE"

    # Check if jobs file is not empty
    if [[ ! -s "$JOBS_FILE" ]]; then
        log_error "Jobs file is empty: $JOBS_FILE"
        exit 1
    fi
    log_info "  [OK] Jobs file is not empty"

    # Check if AutoSys env script exists
    if [[ ! -f "$AUTOSYS_ENV_SCRIPT" ]]; then
        log_error "AutoSys env script not found: $AUTOSYS_ENV_SCRIPT"
        exit 1
    fi
    log_info "  [OK] AutoSys env script exists"

    # Create log directory if needed
    if [[ ! -d "$LOG_DIR" ]]; then
        mkdir -p "$LOG_DIR"
        log_info "  [OK] Created log directory: $LOG_DIR"
    fi

    # Create temp directory
    mkdir -p "$TEMP_DIR"
    log_info "  [OK] Created temp directory: $TEMP_DIR"

    # Source AutoSys environment
    # shellcheck source=/dev/null
    if ! source "$AUTOSYS_ENV_SCRIPT" 2>/dev/null; then
        log_error "Failed to source AutoSys environment"
        exit 1
    fi
    log_info "  [OK] AutoSys environment sourced"

    # Verify sendevent command is available
    if ! command -v sendevent &> /dev/null; then
        log_error "sendevent command not found. AutoSys may not be properly configured."
        exit 1
    fi
    log_info "  [OK] sendevent command available"

    log_success "All pre-flight checks passed"
}

# =============================================================================
# LOAD JOB NAMES FROM TXT FILE
# =============================================================================
load_job_names() {
    log_info "Loading job names from file: $JOBS_FILE"

    # Read job names from .txt file (one per line)
    JOB_NAMES=()
    while IFS= read -r job_name || [[ -n "$job_name" ]]; do
        # Skip empty lines and comments
        job_name=$(echo "$job_name" | xargs)  # Trim whitespace
        if [[ -n "$job_name" ]] && [[ ! "$job_name" =~ ^# ]]; then
            JOB_NAMES+=("$job_name")
        fi
    done < "$JOBS_FILE"

    TOTAL_JOBS=${#JOB_NAMES[@]}

    if [[ $TOTAL_JOBS -eq 0 ]]; then
        log_error "No jobs found in file: $JOBS_FILE"
        exit 1
    fi

    log_success "Loaded $TOTAL_JOBS jobs from file"
    log_info "Sample jobs (first 5):"
    for i in "${JOB_NAMES[@]:0:5}"; do
        log_info "  - $i"
    done
    if [[ $TOTAL_JOBS -gt 5 ]]; then
        log_info "  ... and $((TOTAL_JOBS - 5)) more"
    fi
}

# =============================================================================
# DIVIDE JOBS INTO BATCHES
# =============================================================================
divide_into_batches() {
    log_info "Dividing $TOTAL_JOBS jobs into $NUM_THREADS batches..."

    local batch_size=$(( (TOTAL_JOBS + NUM_THREADS - 1) / NUM_THREADS ))  # Ceiling division

    for ((i = 0; i < NUM_THREADS; i++)); do
        local start_idx=$((i * batch_size))
        local end_idx=$((start_idx + batch_size))

        if [[ $start_idx -ge $TOTAL_JOBS ]]; then
            break
        fi

        if [[ $end_idx -gt $TOTAL_JOBS ]]; then
            end_idx=$TOTAL_JOBS
        fi

        local batch_file="${TEMP_DIR}/batch_${i}.txt"
        local count=0

        for ((j = start_idx; j < end_idx; j++)); do
            echo "${JOB_NAMES[$j]}" >> "$batch_file"
            ((count++))
        done

        log_info "  Thread $((i + 1)): Jobs $((start_idx + 1))-$end_idx ($count jobs)"
    done

    # Count actual batches created
    ACTUAL_BATCHES=$(ls -1 "${TEMP_DIR}"/batch_*.txt 2>/dev/null | wc -l)
    log_success "Created $ACTUAL_BATCHES batches"
}

# =============================================================================
# PROCESS A SINGLE JOB (WITH RETRY)
# =============================================================================
process_job() {
    local job_name=$1
    local thread_id=$2
    local result_file=$3

    local attempt=0
    local success=false

    while [[ $attempt -lt $MAX_RETRIES ]] && [[ "$success" == "false" ]]; do
        ((attempt++))

        if [[ "$DRY_RUN" == "true" ]]; then
            log_thread "$thread_id" "[DRY-RUN] Would execute: sendevent -E CHANGE_STATUS -s INACTIVE -J $job_name"
            success=true
        else
            # Execute sendevent command
            local output
            output=$(sendevent -E CHANGE_STATUS -s INACTIVE -J "$job_name" 2>&1)
            local exit_code=$?

            if [[ $exit_code -eq 0 ]]; then
                success=true
            else
                if [[ $attempt -lt $MAX_RETRIES ]]; then
                    log_thread "$thread_id" "Attempt $attempt failed for $job_name, retrying in ${RETRY_DELAY}s..."
                    sleep "$RETRY_DELAY"
                fi
            fi
        fi
    done

    # Write result to thread's result file (thread-safe since each thread has its own file)
    if [[ "$success" == "true" ]]; then
        echo "SUCCESS:$job_name" >> "$result_file"
    else
        echo "FAILED:$job_name" >> "$result_file"
    fi
}

# =============================================================================
# WORKER FUNCTION (PROCESSES A BATCH)
# =============================================================================
process_batch() {
    local thread_id=$1
    local batch_file=$2
    local result_file="${TEMP_DIR}/result_${thread_id}.txt"

    # Initialize result file
    > "$result_file"

    local total_in_batch
    total_in_batch=$(wc -l < "$batch_file")
    local processed=0
    local success_count=0
    local fail_count=0

    log_thread "$thread_id" "Starting - Processing $total_in_batch jobs"

    local start_time
    start_time=$(date +%s)

    while IFS= read -r job_name; do
        if [[ -n "$job_name" ]]; then
            process_job "$job_name" "$thread_id" "$result_file"
            ((processed++))

            # Progress update every 50 jobs
            if [[ $((processed % 50)) -eq 0 ]] || [[ $processed -eq $total_in_batch ]]; then
                local current_success
                local current_fail
                current_success=$(grep -c "^SUCCESS:" "$result_file" 2>/dev/null || echo 0)
                current_fail=$(grep -c "^FAILED:" "$result_file" 2>/dev/null || echo 0)

                local elapsed=$(($(date +%s) - start_time))
                local rate
                if [[ $elapsed -gt 0 ]]; then
                    rate=$(echo "scale=2; $processed / $elapsed" | bc)
                else
                    rate="N/A"
                fi

                log_thread "$thread_id" "Progress: $processed/$total_in_batch (success=$current_success, failed=$current_fail, rate=${rate} jobs/sec)"
            fi
        fi
    done < "$batch_file"

    local end_time
    end_time=$(date +%s)
    local total_elapsed=$((end_time - start_time))

    local final_success
    local final_fail
    final_success=$(grep -c "^SUCCESS:" "$result_file" 2>/dev/null || echo 0)
    final_fail=$(grep -c "^FAILED:" "$result_file" 2>/dev/null || echo 0)

    log_thread "$thread_id" "COMPLETED - success=$final_success, failed=$final_fail, time=${total_elapsed}s"
}

# =============================================================================
# PARALLEL EXECUTION
# =============================================================================
run_parallel() {
    log_info "========================================================================"
    log_info "  STARTING PARALLEL EXECUTION - $ACTUAL_BATCHES THREADS"
    log_info "========================================================================"

    local pids=()
    local start_time
    start_time=$(date +%s)

    # Launch all threads
    for ((i = 0; i < ACTUAL_BATCHES; i++)); do
        local batch_file="${TEMP_DIR}/batch_${i}.txt"
        local thread_id=$((i + 1))

        if [[ -f "$batch_file" ]]; then
            process_batch "$thread_id" "$batch_file" &
            pids+=($!)
            log_info "Launched Thread $thread_id (PID: ${pids[-1]})"
        fi
    done

    log_info "All $ACTUAL_BATCHES threads launched. Waiting for completion..."
    log_info "========================================================================"

    # Wait for all threads to complete
    local failed_threads=0
    for pid in "${pids[@]}"; do
        if ! wait "$pid"; then
            ((failed_threads++))
        fi
    done

    local end_time
    end_time=$(date +%s)
    local total_elapsed=$((end_time - start_time))

    log_info "========================================================================"
    log_info "All threads completed in ${total_elapsed} seconds"
    if [[ $failed_threads -gt 0 ]]; then
        log_warning "$failed_threads thread(s) exited with errors"
    fi
}

# =============================================================================
# AGGREGATE RESULTS
# =============================================================================
aggregate_results() {
    log_info "========================================================================"
    log_info "AGGREGATING RESULTS"
    log_info "========================================================================"

    local total_success=0
    local total_failed=0

    # Initialize failures CSV
    echo "job_name,status,timestamp" > "$FAILURES_CSV"

    # Process each thread's result file
    for result_file in "${TEMP_DIR}"/result_*.txt; do
        if [[ -f "$result_file" ]]; then
            local thread_success
            local thread_failed
            thread_success=$(grep -c "^SUCCESS:" "$result_file" 2>/dev/null || echo 0)
            thread_failed=$(grep -c "^FAILED:" "$result_file" 2>/dev/null || echo 0)

            total_success=$((total_success + thread_success))
            total_failed=$((total_failed + thread_failed))

            # Extract failed jobs and add to CSV
            grep "^FAILED:" "$result_file" 2>/dev/null | while IFS=: read -r _ job_name; do
                echo "$job_name,FAILED,$(date '+%Y-%m-%d %H:%M:%S')" >> "$FAILURES_CSV"
            done
        fi
    done

    log_info "========================================================================"
    log_info "FINAL SUMMARY"
    log_info "========================================================================"
    log_info "Jobs File:       $JOBS_FILE"
    log_info "Total Jobs:      $TOTAL_JOBS"
    log_info "Threads Used:    $ACTUAL_BATCHES"
    log_info "Max Retries:     $MAX_RETRIES"
    log_info "------------------------------------------------------------------------"
    log_success "Successful:      $total_success"
    if [[ $total_failed -gt 0 ]]; then
        log_error "Failed:          $total_failed"
        log_info "Failed jobs written to: $FAILURES_CSV"
    else
        log_info "Failed:          0"
    fi
    log_info "------------------------------------------------------------------------"
    log_info "Log file:        $LOG_FILE"
    log_info "========================================================================"

    # Set exit code based on failures
    if [[ $total_failed -gt 0 ]]; then
        SCRIPT_EXIT_CODE=1
    else
        SCRIPT_EXIT_CODE=0
    fi
}

# =============================================================================
# CLEANUP
# =============================================================================
cleanup() {
    log_info "Cleaning up temporary files..."
    rm -rf "$TEMP_DIR"
    log_info "Cleanup complete"
}

# =============================================================================
# TRAP FOR CLEANUP ON EXIT/ERROR
# =============================================================================
trap cleanup EXIT

# =============================================================================
# MAIN EXECUTION
# =============================================================================
main() {
    echo ""
    echo "========================================================================"
    echo "  AutoSys Job Inactivation - Parallel Execution"
    echo "  Started: $(date '+%Y-%m-%d %H:%M:%S')"
    echo "========================================================================"
    echo ""

    # Parse command line arguments
    parse_arguments "$@"

    # Create log file
    mkdir -p "$LOG_DIR"
    touch "$LOG_FILE"

    log_info "Configuration:"
    log_info "  Jobs File:     $JOBS_FILE"
    log_info "  Threads:       $NUM_THREADS"
    log_info "  Max Retries:   $MAX_RETRIES"
    log_info "  Dry Run:       $DRY_RUN"
    log_info "  Log File:      $LOG_FILE"

    # Run pre-flight checks
    preflight_checks

    # Load job names from txt file
    load_job_names

    # Divide jobs into batches
    divide_into_batches

    # Execute in parallel
    run_parallel

    # Aggregate and report results
    aggregate_results

    echo ""
    echo "========================================================================"
    echo "  Completed: $(date '+%Y-%m-%d %H:%M:%S')"
    echo "========================================================================"
    echo ""

    exit $SCRIPT_EXIT_CODE
}

# Run main function with all arguments
main "$@"
